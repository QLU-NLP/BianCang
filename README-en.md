# æ‰ä»“ä¸­åŒ»å¤§æ¨¡å‹

<div align="center">
    <p>
    <img src="assets/BianCang-logo.png" width="500px"/>
    </p>
    </div>
<div align="center">
  ğŸŒ<a href="README.md">zh</a> | <a href="README-en.md">en</a>
</div>

## ğŸ‰æ–°é—»

- [11/18/2024] æˆ‘ä»¬åœ¨è¯¥ä»“åº“å‘å¸ƒäº†æ‰ä»“ç³»åˆ—æ¨¡å‹ï¼ŒåŒ…æ‹¬BianCang-Qwen2-7Bã€BianCang-Qwen2-7B-Instructã€BianCang-Qwen2.5-7Bã€BianCang-Qwen2.5-7B-Instructã€‚
- [11/18/2024] æˆ‘ä»¬å…¬å¼€äº†ChP-TCMæ•°æ®é›†ã€‚

## ğŸ“…æœªæ¥è§„åˆ’

- [ ] å¼€æºBianCang-Qwen2.5-14Bã€BianCang-Qwen2.5-14B-Instructã€‚

## ğŸ’¡ä»‹ç»

ä½ å¥½ï¼Œæ¬¢è¿æ¥åˆ°æ‰ä»“ä¸­åŒ»å¤§æ¨¡å‹çš„å¼€æºä»“åº“ã€‚

ä¸ºæ¨åŠ¨å¤§è¯­è¨€æ¨¡å‹åœ¨ä¼ ç»Ÿä¸­åŒ»é¢†åŸŸçš„è½åœ°åº”ç”¨ï¼Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œç–¾ç—…è¯Šæ–­ï¼Œè¾…åŠ©æ‚£è€…è¿›è¡Œè‡ªæˆ‘è¯„ä¼°ï¼Œæ¨åŠ¨å¤§æ¨¡å‹èµ‹èƒ½ä¼ ç»Ÿä¸­åŒ»ï¼Œæˆ‘ä»¬åœ¨è¯¥ä»“åº“æ¨å‡ºäº†**æ‰ä»“**ç³»åˆ—ä¸­åŒ»å¤§æ¨¡å‹ã€‚æ‰ä»“æ˜¯å¤ä»£ååŒ»æ‰é¹Šã€ä»“å…¬çš„å¹¶ç§°ï¼Œæ³›æŒ‡ååŒ»ã€‚æˆ‘ä»¬æœŸå¾…æ‰ä»“ä¸­åŒ»å¤§æ¨¡å‹èƒ½å¤Ÿåœ¨å»¶ç»­ä¸­åŒ»ä¼ æ‰¿å’Œæå‡æˆ‘å›½äººæ°‘åŒ»ç–—å¥åº·æ°´å¹³æ–¹é¢åšå‡ºä¸€å®šçš„è´¡çŒ®ã€‚

æ‰ä»“ä»¥Qwen2/2.5ä½œä¸ºåŸºåº§ï¼Œé‡‡ç”¨å…ˆæ³¨å…¥é¢†åŸŸçŸ¥è¯†å†è¿›è¡ŒçŸ¥è¯†æ¿€æ´»å’Œå¯¹é½çš„ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ³•è€Œå¾—åˆ°ã€‚æ‰ä»“åœ¨ä¸­åŒ»è¾¨ç—…è¾¨è¯ç­‰ä¸­åŒ»ç‰¹è‰²ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨å„ç§åŒ»å­¦æ‰§ç…§è€ƒè¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

æˆ‘ä»¬åœ¨è¯¥ä»“åº“ä¸­å¼€æºä»¥ä¸‹èµ„æºï¼š

- æ‰ä»“åŸºåº§æ¨¡å‹æƒé‡ï¼šåŒ…æ‹¬BianCang-Qwen2-7Bã€BianCang-Qwen2.5-7Bã€‚

- æ‰ä»“æŒ‡ä»¤ç²¾è°ƒæ¨¡å‹æƒé‡ï¼šåŒ…æ‹¬BianCang-Qwen2-7B-Instructã€BianCang-Qwen2.5-7B-Instructã€‚


## ğŸ¤–æ¨¡å‹

ä½ å¯ä»¥åœ¨Huggingfaceä¸Šä¸‹è½½æ‰ä»“çš„æ¨¡å‹æƒé‡ï¼š

| æ¨¡å‹                         | åŸºåº§                | é“¾æ¥                                                         |
| ---------------------------- | ------------------- | ------------------------------------------------------------ |
| BianCang-Qwen2-7B            | Qwen2-7B            | [anonymous] |
| BianCang-Qwen2-7B-Instruct   | BianCang-Qwen2-7B   | [anonymous] |
| BianCang-Qwen2.5-7B          | Qwen2.5-7B          | [anonymous] |
| BianCang-Qwen2.5-7B-Instruct | BianCang-Qwen2.5-7B | [anonymous] |

ä¹Ÿå¯ä»¥åœ¨ModelScopeä¸Šä¸‹è½½æ‰ä»“çš„æ¨¡å‹æƒé‡ï¼Œè¿™å¯¹å›½å†…ç½‘ç»œæ›´å‹å¥½ï¼š

| æ¨¡å‹                         | åŸºåº§                | é“¾æ¥                                                         |
| ---------------------------- | ------------------- | ------------------------------------------------------------ |
| BianCang-Qwen2-7B            | Qwen2-7B            | [anonymous] |
| BianCang-Qwen2-7B-Instruct   | BianCang-Qwen2-7B   | [anonymous] |
| BianCang-Qwen2.5-7B          | Qwen2.5-7B          | [anonymous] |
| BianCang-Qwen2.5-7B-Instruct | BianCang-Qwen2.5-7B | [anonymous] |

## ğŸš€æ¨ç†

### ä½¿ç”¨SWIFT

#### ç¯å¢ƒå®‰è£…

åœ¨[Release v2.4.2 Â· modelscope/ms-swift](https://github.com/modelscope/ms-swift/releases/tag/v2.4.2)å¤„ä¸‹è½½SWIFTæºç ï¼Œåˆ‡æ¢åˆ°å¯¹åº”ç›®å½•ï¼Œç„¶åæ‰§è¡Œå®‰è£…å‘½ä»¤ï¼š

```shell
cd swift
pip install -e .
```

ä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„GPUé©±åŠ¨ç‰ˆæœ¬å»é€‰æ‹©åˆé€‚çš„torchç‰ˆæœ¬è¿›è¡Œæ›¿æ¢ï¼ŒSWIFTè‡³å°‘éœ€è¦torch >= 1.13ï¼Œæ¨ètorch >= 2.0.0ã€‚

æ³¨æ„ï¼šç”±äºæˆ‘ä»¬è¿›è¡ŒSFTè®­ç»ƒæ—¶ä½¿ç”¨çš„Chat Templateä¸º*qwen*ï¼Œå› æ­¤å¦‚æœä½ ä½¿ç”¨çš„SWIFTç‰ˆæœ¬å¤§äºæˆ‘ä»¬æä¾›çš„ç‰ˆæœ¬ï¼Œå¯èƒ½ä¼šé‡åˆ°Qwen2.5 Chat Templateä¸å¯¹åº”çš„é—®é¢˜ï¼Œè¯·æ‰‹åŠ¨å°†Chat TemplateæŒ‡å®šä¸º*qwen*è€Œä¸æ˜¯*qwen2_5*ã€‚å…·ä½“åŸå› å‚è€ƒï¼š[fix qwen2.5 template by Jintao-Huang Â· Pull Request #2081 Â· modelscope/ms-swift](https://github.com/modelscope/ms-swift/pull/2081)

#### æ¨ç†æ–¹å¼1-ä»£ç æ¨ç†

```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

from swift.llm import (
    get_model_tokenizer, get_template, inference, ModelType
)
from swift.utils import seed_everything

model_type = ModelType.qwen2_5_7b_instruct
template_type = 'qwen'

model_id_or_path = 'BianCang-Qwen2.5-7B-Instruct'
model, tokenizer = get_model_tokenizer(model_type, model_id_or_path=model_id_or_path, model_kwargs={'device_map': 'auto'})
model.generation_config.max_new_tokens = 256

template = get_template(template_type, tokenizer)
seed_everything(42)
query = 'ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ'
response, history = inference(model, template, query)
print(f'query: {query}')
print(f'response: {response}')
query = 'ä¸‹é¢æ˜¯ä¸€åæ‚£è€…çš„åŸºæœ¬æƒ…å†µã€‚å¹´é¾„ï¼š78å²ï¼Œæ€§åˆ«ï¼šå¥³ã€‚ä¸» è¯‰ï¼šæ´»åŠ¨åèƒ¸ç—›ä¸€å‘¨ã€‚ç°ç—…å²ï¼šæ‚£è€…ä¸€å‘¨å‰æ´»åŠ¨åå‡ºç°èƒ¸å£éšéšä½œç—›ï¼Œå¦‚é’ˆåˆºæ ·ä¹åŠ›æ°”çŸ­ï¼Œæ´»åŠ¨åæ±—å‡ºï¼Œåå¤´ç—›ã€‚ä¸­åŒ»æœ›é—»åˆ‡è¯Šï¼šè¡¨æƒ…è‡ªç„¶ï¼Œé¢è‰²çº¢æ¶¦ï¼Œå½¢ä½“æ­£å¸¸,è¯­æ°”æ¸…,æ°”æ¯å¹³ï¼›æ— å¼‚å¸¸æ°”å‘³,èˆŒæš—çº¢ï¼Œè‹”å°‘ã€‚è¯·ä½ æ ¹æ®ä¸Šè¿°æ‚£è€…çš„ä¸»è¯‰ã€ç—…å²å’Œä¸­åŒ»æœ›é—»åˆ‡è¯Šæƒ…å†µï¼Œåˆ¤æ–­è¯¥æ‚£è€…çš„ä¸»è¦ä¸­åŒ»ç–¾ç—…å’Œä¸­åŒ»è¯å‹ï¼Œå¹¶ç»™å‡ºä¸­åŒ»è¾¨ç—…è¾¨è¯çš„ä¾æ®ã€‚'
response, history = inference(model, template, query, history)
print(f'query: {query}')
print(f'response: {response}')
print(f'history: {history}')
```

è¾“å‡ºï¼š

```
query: ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ
response: ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªåä¸ºæ‰ä»“ä¸­åŒ»å¤§æ¨¡å‹çš„äººå·¥æ™ºèƒ½ï¼Œç”±[anonymous]ç ”å‘ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œä»¥ä¾¿ä¸äººç±»è¿›è¡Œä¸­åŒ»è¾©è¯ã€ä¸­åŒ»å¤„æ–¹æ¨èã€ä¸­åŒ»çŸ¥è¯†é—®ç­”ã€ä¸­åŒ»é—®é¢˜å’¨è¯¢ç­‰æ–¹é¢çš„å¯¹è¯äº¤æµï¼Œè¾…åŠ©äººä»¬å®Œæˆç–¾ç—…è¯Šæ–­ç›¸å…³çš„ä»»åŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ
query: ä¸‹é¢æ˜¯ä¸€åæ‚£è€…çš„åŸºæœ¬æƒ…å†µã€‚å¹´é¾„ï¼š78å²ï¼Œæ€§åˆ«ï¼šå¥³ã€‚ä¸» è¯‰ï¼šæ´»åŠ¨åèƒ¸ç—›ä¸€å‘¨ã€‚ç°ç—…å²ï¼šæ‚£è€…ä¸€å‘¨å‰æ´»åŠ¨åå‡ºç°èƒ¸å£éšéšä½œç—›ï¼Œå¦‚é’ˆåˆºæ ·ä¹åŠ›æ°”çŸ­ï¼Œæ´»åŠ¨åæ±—å‡ºï¼Œåå¤´ç—›ã€‚ä¸­åŒ»æœ›é—»åˆ‡è¯Šï¼šè¡¨æƒ…è‡ªç„¶ï¼Œé¢è‰²çº¢æ¶¦ï¼Œå½¢ä½“æ­£å¸¸,è¯­æ°”æ¸…,æ°”æ¯å¹³ï¼›æ— å¼‚å¸¸æ°”å‘³,èˆŒæš—çº¢ï¼Œè‹”å°‘ã€‚è¯·ä½ æ ¹æ®ä¸Šè¿°æ‚£è€…çš„ä¸»è¯‰ã€ç—…å²å’Œä¸­åŒ»æœ›é—»åˆ‡è¯Šæƒ…å†µï¼Œåˆ¤æ–­è¯¥æ‚£è€…çš„ä¸»è¦ä¸­åŒ»ç–¾ç—…å’Œä¸­åŒ»è¯å‹ï¼Œå¹¶ç»™å‡ºä¸­åŒ»è¾¨ç—…è¾¨è¯çš„ä¾æ®ã€‚
response: æ ¹æ®ä¸­åŒ»çš„è¯Šæ–­æ–¹æ³•ï¼Œæ‚£è€…æ‚£æœ‰èƒ¸ç—¹å¿ƒç—›ï¼Œä¸­åŒ»è¯å‹å±äºæ°”è™šè¡€ç˜€è¯ã€‚ç»¼åˆè„‰è¯ï¼Œå››è¯Šåˆå‚ï¼Œæœ¬ç—…å½“å±ç¥–å›½åŒ»å­¦â€œèƒ¸ç—¹å¿ƒç—›ç—…â€èŒƒç•´ï¼Œè¯å±â€œæ°”è™šè¡€ç˜€â€ã€‚æ‚£è€…ç´ ä½“è™šå¼±ï¼Œä¹…ç—…ä¼¤æ­£ï¼Œä¼¤åŠå¿ƒæ°”ï¼Œå¿ƒæ°”è¡°å¾®ï¼Œæœºèƒ½ä¸å¥ï¼Œè‡´é˜´é‚ªæ˜“äºä¸Šä¹˜é˜³ä½ï¼Œå†µå¿ƒè„‰ä¸ºå®—æ°”ä¹‹æ‰€ï¼Œç™¾è„‰æœä¼šä¹‹æ¢ï¼Œå®—æ°”çš„é¼“åŠ¨å½¢æˆäº†å¿ƒæ°”æ¨åŠ¨è¡€æ¶²è¿è¡Œå…¨èº«ï¼Œå¿ƒæ°”ä¸è¶³åˆ™è¡€è¡Œæ— åŠ›ç˜€æ»ï¼Œå‘ä¸ºæœ¬ç—…ï¼ŒèˆŒè„‰ä¿±ä¸ºä½è¯ã€‚
history: [['ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ', 'ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªåä¸ºæ‰ä»“ä¸­åŒ»å¤§æ¨¡å‹çš„äººå·¥æ™ºèƒ½ï¼Œç”±[anonymous]ç ”å‘ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œä»¥ä¾¿ä¸äººç±»è¿›è¡Œä¸­åŒ»è¾©è¯ã€ä¸­åŒ»å¤„æ–¹æ¨èã€ä¸­åŒ»çŸ¥è¯†é—®ç­”ã€ä¸­åŒ»é—®é¢˜å’¨è¯¢ç­‰æ–¹é¢çš„å¯¹è¯äº¤æµï¼Œè¾…åŠ©äººä»¬å®Œæˆç–¾ç—…è¯Šæ–­ç›¸å…³çš„ä»»åŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ'], ['ä¸‹é¢æ˜¯ä¸€åæ‚£è€…çš„åŸºæœ¬æƒ…å†µã€‚å¹´é¾„ï¼š78å²ï¼Œæ€§åˆ«ï¼šå¥³ã€‚ä¸» è¯‰ï¼šæ´»åŠ¨åèƒ¸ç—›ä¸€å‘¨ã€‚ç°ç—…å²ï¼šæ‚£è€…ä¸€å‘¨å‰æ´»åŠ¨åå‡ºç°èƒ¸å£éšéšä½œç—›ï¼Œå¦‚é’ˆåˆºæ ·ä¹åŠ›æ°”çŸ­ï¼Œæ´»åŠ¨åæ±—å‡ºï¼Œåå¤´ç—›ã€‚ä¸­åŒ»æœ›é—»åˆ‡è¯Šï¼šè¡¨æƒ…è‡ªç„¶ï¼Œé¢è‰²çº¢æ¶¦ï¼Œå½¢ä½“æ­£å¸¸,è¯­æ°”æ¸…,æ°”æ¯å¹³ï¼›æ— å¼‚å¸¸æ°”å‘³,èˆŒæš—çº¢ï¼Œè‹”å°‘ã€‚è¯·ä½ æ ¹æ®ä¸Šè¿°æ‚£è€…çš„ä¸»è¯‰ã€ç—…å²å’Œä¸­åŒ»æœ›é—»åˆ‡è¯Šæƒ…å†µï¼Œåˆ¤æ–­è¯¥æ‚£è€…çš„ä¸»è¦ä¸­åŒ»ç–¾ç—…å’Œä¸­åŒ»è¯å‹ï¼Œå¹¶ç»™å‡ºä¸­åŒ»è¾¨ç—…è¾¨è¯çš„ä¾æ®ã€‚', 'æ ¹æ®ä¸­åŒ»çš„è¯Šæ–­æ–¹æ³•ï¼Œæ‚£è€…æ‚£æœ‰èƒ¸ç—¹å¿ƒç—›ï¼Œä¸­åŒ»è¯å‹å±äºæ°”è™šè¡€ç˜€è¯ã€‚ç»¼åˆè„‰è¯ï¼Œå››è¯Šåˆå‚ï¼Œæœ¬ç—…å½“å±ç¥–å›½åŒ»å­¦â€œèƒ¸ç—¹å¿ƒç—›ç—…â€èŒƒç•´ï¼Œè¯å±â€œæ°”è™šè¡€ç˜€â€ã€‚æ‚£è€…ç´ ä½“è™šå¼±ï¼Œä¹…ç—…ä¼¤æ­£ï¼Œä¼¤åŠå¿ƒæ°”ï¼Œå¿ƒæ°”è¡°å¾®ï¼Œæœºèƒ½ä¸å¥ï¼Œè‡´é˜´é‚ªæ˜“äºä¸Šä¹˜é˜³ä½ï¼Œå†µå¿ƒè„‰ä¸ºå®—æ°”ä¹‹æ‰€ï¼Œç™¾è„‰æœä¼šä¹‹æ¢ï¼Œå®—æ°”çš„é¼“åŠ¨å½¢æˆäº†å¿ƒæ°”æ¨åŠ¨è¡€æ¶²è¿è¡Œå…¨èº«ï¼Œå¿ƒæ°”ä¸è¶³åˆ™è¡€è¡Œæ— åŠ›ç˜€æ»ï¼Œå‘ä¸ºæœ¬ç—…ï¼ŒèˆŒè„‰ä¿±ä¸ºä½è¯ã€‚']]
```

#### æ¨ç†æ–¹å¼2-éƒ¨ç½²API

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤éƒ¨ç½²APIï¼š

```shell
CUDA_VISIBLE_DEVICES=0 swift deploy --model_type qwen2_5-7b-instruct --model_id_or_path BianCang-Qwen2.5-7B-Instruct --port 8090 --template_type qwen
```

ä½¿ç”¨curlè¿›è¡Œæµ‹è¯•ï¼š

```shell
curl http://localhost:8090/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{
"model": "qwen2_5-7b-instruct",
"messages": [{"role": "user", "content": "ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ"}],
"max_tokens": 256,
"temperature": 0.3
}'
```

å“åº”å¦‚ä¸‹ï¼š

```json
{"model":"qwen2_5-7b-instruct",
"choices":[{"index":0,"message":{"role":"assistant","content":"ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªåä¸ºæ‰ä»“ä¸­åŒ»å¤§æ¨¡å‹çš„äººå·¥æ™ºèƒ½ï¼Œç”±[anonymous]ç ”å‘ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œä»¥ä¾¿ä¸äººç±»è¿›è¡Œä¸­åŒ»è¾©è¯ã€ä¸­åŒ»å¤„æ–¹æ¨èã€ä¸­åŒ»çŸ¥è¯†é—®ç­”ã€ä¸­åŒ»é—®é¢˜å’¨è¯¢ç­‰æ–¹é¢çš„å¯¹è¯äº¤æµï¼Œè¾…åŠ©äººä»¬å®Œæˆç–¾ç—…è¯Šæ–­ç›¸å…³çš„ä»»åŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
"tool_calls":null},"finish_reason":null,"logprobs":null}],
"usage":{"prompt_tokens":24,"completion_tokens":92,"total_tokens":116},
"id":"chatcmpl-6b4a02dee57a42238b27b5c40085df16",
"object":"chat.completion","created":1730209011}
```

ä½¿ç”¨ä»£ç è¿›è¡Œæµ‹è¯•ï¼š

```python
from swift.llm import get_model_list_client, XRequestConfig, inference_client

model_list = get_model_list_client(port=8090)
model_type = model_list.data[0].id
print(f'model_type: {model_type}')

query = "ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ"
request_config = XRequestConfig(seed=42)
resp = inference_client(model_type, query, request_config=request_config, port=8090)
response = resp.choices[0].message.content
print(f'query: {query}')
print(f'response: {response}')

history = [(query, response)]
query = 'ä¸‹é¢æ˜¯ä¸€åæ‚£è€…çš„åŸºæœ¬æƒ…å†µã€‚å¹´é¾„ï¼š78å²ï¼Œæ€§åˆ«ï¼šå¥³ã€‚ä¸» è¯‰ï¼šæ´»åŠ¨åèƒ¸ç—›ä¸€å‘¨ã€‚ç°ç—…å²ï¼šæ‚£è€…ä¸€å‘¨å‰æ´»åŠ¨åå‡ºç°èƒ¸å£éšéšä½œç—›ï¼Œå¦‚é’ˆåˆºæ ·ä¹åŠ›æ°”çŸ­ï¼Œæ´»åŠ¨åæ±—å‡ºï¼Œåå¤´ç—›ã€‚ä¸­åŒ»æœ›é—»åˆ‡è¯Šï¼šè¡¨æƒ…è‡ªç„¶ï¼Œé¢è‰²çº¢æ¶¦ï¼Œå½¢ä½“æ­£å¸¸,è¯­æ°”æ¸…,æ°”æ¯å¹³ï¼›æ— å¼‚å¸¸æ°”å‘³,èˆŒæš—çº¢ï¼Œè‹”å°‘ã€‚è¯·ä½ æ ¹æ®ä¸Šè¿°æ‚£è€…çš„ä¸»è¯‰ã€ç—…å²å’Œä¸­åŒ»æœ›é—»åˆ‡è¯Šæƒ…å†µï¼Œåˆ¤æ–­è¯¥æ‚£è€…çš„ä¸»è¦ä¸­åŒ»ç–¾ç—…å’Œä¸­åŒ»è¯å‹ï¼Œå¹¶ç»™å‡ºä¸­åŒ»è¾¨ç—…è¾¨è¯çš„ä¾æ®ã€‚'
request_config = XRequestConfig(stream=True, seed=42)
stream_resp = inference_client(model_type, query, history, request_config=request_config, port=8090)
print(f'query: {query}')
print('response: ', end='')
for chunk in stream_resp:
    print(chunk.choices[0].delta.content, end='', flush=True)
print()
```

è¾“å‡ºå¦‚ä¸‹ï¼š

```
model_type: qwen2_5-7b-instruct
query: ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ
response: ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªåä¸ºæ‰ä»“ä¸­åŒ»å¤§æ¨¡å‹çš„äººå·¥æ™ºèƒ½ï¼Œç”±[anonymous]ç ”å‘ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œä»¥ä¾¿ä¸äººç±»è¿›è¡Œä¸­åŒ»è¾©è¯ã€ä¸­åŒ»å¤„æ–¹æ¨èã€ä¸­åŒ»çŸ¥è¯†é—®ç­”ã€ä¸­åŒ»é—®é¢˜å’¨è¯¢ç­‰æ–¹é¢çš„å¯¹è¯äº¤æµï¼Œè¾…åŠ©äººä»¬å®Œæˆç–¾ç—…è¯Šæ–­ç›¸å…³çš„ä»»åŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ
query: ä¸‹é¢æ˜¯ä¸€åæ‚£è€…çš„åŸºæœ¬æƒ…å†µã€‚å¹´é¾„ï¼š78å²ï¼Œæ€§åˆ«ï¼šå¥³ã€‚ä¸» è¯‰ï¼šæ´»åŠ¨åèƒ¸ç—›ä¸€å‘¨ã€‚ç°ç—…å²ï¼šæ‚£è€…ä¸€å‘¨å‰æ´»åŠ¨åå‡ºç°èƒ¸å£éšéšä½œç—›ï¼Œå¦‚é’ˆåˆºæ ·ä¹åŠ›æ°”çŸ­ï¼Œæ´»åŠ¨åæ±—å‡ºï¼Œåå¤´ç—›ã€‚ä¸­åŒ»æœ›é—»åˆ‡è¯Šï¼šè¡¨æƒ…è‡ªç„¶ï¼Œé¢è‰²çº¢æ¶¦ï¼Œå½¢ä½“æ­£å¸¸,è¯­æ°”æ¸…,æ°”æ¯å¹³ï¼›æ— å¼‚å¸¸æ°”å‘³,èˆŒæš—çº¢ï¼Œè‹”å°‘ã€‚è¯·ä½ æ ¹æ®ä¸Šè¿°æ‚£è€…çš„ä¸»è¯‰ã€ç—…å²å’Œä¸­åŒ»æœ›é—»åˆ‡è¯Šæƒ…å†µï¼Œåˆ¤æ–­è¯¥æ‚£è€…çš„ä¸»è¦ä¸­åŒ»ç–¾ç—…å’Œä¸­åŒ»è¯å‹ï¼Œå¹¶ç»™å‡ºä¸­åŒ»è¾¨ç—…è¾¨è¯çš„ä¾æ®ã€‚
response: æ ¹æ®ä¸­åŒ»çš„è¯Šæ–­æ–¹æ³•ï¼Œæ‚£è€…æ‚£æœ‰èƒ¸ç—¹å¿ƒç—›ï¼Œä¸­åŒ»è¯å‹å±äºæ°”è™šè¡€ç˜€è¯ã€‚ç»¼åˆè„‰è¯ï¼Œå››è¯Šåˆå‚ï¼Œæœ¬ç—…å½“å±ç¥–å›½åŒ»å­¦â€œèƒ¸ç—¹å¿ƒç—›ç—…â€èŒƒç•´ï¼Œè¯å±â€œæ°”è™šè¡€ç˜€â€ã€‚æ‚£è€…ç´ ä½“è™šå¼±ï¼Œä¹…ç—…ä¼¤æ­£ï¼Œä¼¤åŠå¿ƒæ°”ï¼Œå¿ƒæ°”è¡°å¾®ï¼Œæœºèƒ½ä¸å¥ï¼Œè‡´é˜´é‚ªæ˜“äºä¸Šä¹˜é˜³ä½ï¼Œå†µå¿ƒè„‰ä¸ºå®—æ°”ä¹‹æ‰€ï¼Œç™¾è„‰æœä¼šä¹‹æ¢ï¼Œå®—æ°”çš„é¼“åŠ¨å½¢æˆäº†å¿ƒæ°”æ¨åŠ¨è¡€æ¶²è¿è¡Œå…¨èº«ï¼Œå¿ƒæ°”ä¸è¶³åˆ™è¡€è¡Œæ— åŠ›ç˜€æ»ï¼Œå‘ä¸ºæœ¬ç—…ï¼ŒèˆŒè„‰ä¿±ä¸ºä½è¯ã€‚
```

### ä½¿ç”¨Transformers

ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨transformersåŒ…è¿›è¡Œæ¨ç†ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "BianCang-Qwen2.5-7B-Instruct"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = "ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ"
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=256
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)

```

### ä½¿ç”¨Web UI

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€å•çš„æ¼”ç¤ºWeb UIã€‚

å®‰è£…streamlitï¼š

```shell
pip install streamlit
```

ä½¿ç”¨SWIFTéƒ¨ç½²APIï¼š

```shell
CUDA_VISIBLE_DEVICES=0 swift deploy --model_type qwen2_5-7b-instruct --model_id_or_path BianCang-Qwen2.5-7B-Instruct --port 8090 --template_type qwen
```

å¯åŠ¨streamlitï¼š

```shell
streamlit run web_ui.py
```


## ğŸ¥‡ä¸­åŒ»èƒ½åŠ›æµ‹è¯•

<table border="1" cellpadding="5" cellspacing="0">
  <thead>
    <tr>
      <th rowspan="2">Model</th>
      <th colspan="4">TCM Syndrome Differentiation</th>
      <th colspan="4">TCM Disease Diagnosis</th>
      <th colspan="4">TCM Exam</th>
    </tr>
    <tr>
      <th colspan="2">TCMSD <br>Acc.(%)</th>
      <th colspan="2">TCMSD-BC<br> Acc.(%)</th>
      <th colspan="2">TCMDD<br> Acc.(%)</th>
      <th colspan="2">TCMDD-BC<br> Acc.(%)</th>
      <th colspan="2">MLEC-TCM<br> Acc.(%)</th>
      <th colspan="2">MLEC-CWM<br> Acc.(%)</th>
    </tr>
    <tr>
        <th></th><th>DI</th><th>CoT</th><th>DI</th><th>CoT</th><th>DI</th><th>CoT</th><th>DI</th><th>CoT</th><th>ZS</th><th>FS</th><th>ZS</th><th>FS</th>
    </tr>
  </thead>
  <tbody align="center" valign="center">
    <tr><td>GPT-4</td><td>24.53</td><td>45.21</td><td>16.67</td><td>70.73</td><td>27.83</td><td>54.54</td><td>41.80</td><td>68.33</td><td>74.70</td><td>76.35</td><td>76.26</td><td>76.37</td></tr>
    <tr><td>Qwen2-7B</td><td>31.74</td><td>27.18</td><td>32.73</td><td>28.40</td><td>41.60</td><td>54.59</td><td>74.87</td><td>77.93</td><td>86.01</td><td>89.18</td><td>84.45</td><td>87.89</td></tr>
    <tr><td>Qwen2-7B-Instruct</td><td>25.70</td><td>33.41</td><td>14.27</td><td>57.00</td><td>32.87</td><td>52.92</td><td>60.40</td><td>60.13</td><td>83.61</td><td>84.22</td><td>79.89</td><td>82.99</td></tr>
    <tr><td>Qwen2.5-7B</td><td>30.44</td><td>21.29</td><td>17.87</td><td>35.73</td><td>23.71</td><td>43.88</td><td>63.87</td><td>71.27</td><td>83.32</td><td>85.52</td><td>82.02</td><td>84.04</td></tr>
    <tr><td>Qwen2.5-7B-Instruct</td><td>24.30</td><td>32.19</td><td>9.93</td><td>57.07</td><td>36.29</td><td>51.51</td><td>62.93</td><td>55.53</td><td>78.72</td><td>79.88</td><td>77.27</td><td>78.43</td></tr>
    <tr><td>Qwen2.5-14B</td><td>35.62</td><td>25.21</td><td>33.93</td><td>30.13</td><td>24.33</td><td>36.64</td><td>33.33</td><td>32.80</td><td>86.59</td><td>89.93</td><td>87.10</td><td>90.06</td></tr>
    <tr><td>Qwen2.5-14B-Instruct</td><td>25.94</td><td>35.03</td><td>16.07</td><td>60.00</td><td>38.30</td><td>49.31</td><td>46.27</td><td>53.67</td><td>82.25</td><td>84.81</td><td>81.79</td><td>85.68</td></tr>
    <tr><td>BianCang-Qwen2-7B</td><td>42.14</td><td>30.30</td><td>57.80</td><td>48.00</td><td>43.73</td><td>54.67</td><td>74.73</td><td>80.67</td><td>90.86</td><td>91.87</td><td>89.08</td><td>90.36</td></tr>
    <tr><td>BianCang-Qwen2-7B-Instruct</td><td>68.88</td><td>75.96</td><td>57.33</td><td>75.40</td><td>64.42</td><td>77.71</td><td><b>89.07</b></td><td>85.67</td><td><b>92.39</b></td><td><b>92.39</b></td><td>91.14</td><td>91.48</td></tr>
    <tr><td>BianCang-Qwen2.5-7B</td><td>46.57</td><td>26.72</td><td>52.93</td><td>45.47</td><td>49.80</td><td>53.15</td><td>68.13</td><td>61.73</td><td>86.46</td><td>86.30</td><td>83.93</td><td>85.35</td></tr>
    <tr><td>BianCang-Qwen2.5-7B-Instruct</td><td>78.90</td><td><b>82.10</b></td><td><b>66.73</b></td><td><b>77.73</b></td><td>73.73</td><td><b>82.65</b></td><td>87.87</td><td><b>89.40</b></td><td>90.22</td><td>90.57</td><td>90.32</td><td>90.62</td></tr>
    <tr><td>BianCang-Qwen2.5-14B</td><td>43.77</td><td>33.96</td><td>61.93</td><td>53.47</td><td>66.61</td><td>60.39</td><td>82.93</td><td>77.07</td><td>89.28</td><td>90.86</td><td>89.42</td><td>90.58</td></tr>
    <tr><td>BianCang-Qwen2.5-14B-Instruct</td><td><b>79.38</b></td><td>75.54</td><td>62.27</td><td>70.73</td><td><b>77.63</b></td><td>82.05</td><td>86.33</td><td>88.73</td><td>92.29</td><td>92.29</td><td><b>92.75</b></td><td><b>92.86</b></td></tr>
  </tbody>
</table>

<br>

<table border="1">
  <tr>
    <th>Model</th>
    <th>CMB Acc.(%)</th>
    <th colspan="2">MLEC-Clinic <br>Acc.(%)</th>
    <th colspan="2">MLEC-PublicHealth<br> Acc.(%)</th>
    <th colspan="2">MLEC-Stomatology<br> Acc.(%)</th>
  </tr>
  <tr>
    <th></th>
    <th>ZS/FS</th>
    <th>ZS</th>
    <th>FS</th>
    <th>ZS</th>
    <th>FS</th>
    <th>ZS</th>
    <th>FS</th>
  </tr>
  <tr>
    <td>GPT-4</td>
    <td>59.46*</td>
    <td>82.63</td>
    <td>82.69</td>
    <td>81.55</td>
    <td>82.58</td>
    <td>72.97</td>
    <td>75.43</td>
  </tr>
  <tr>
    <td>Qwen2-7B</td>
    <td>81.63</td>
    <td>87.63</td>
    <td>90.63</td>
    <td>82.63</td>
    <td>86.79</td>
    <td>80.34</td>
    <td>84.65</td>
  </tr>
  <tr>
    <td>Qwen2-7B-Instruct</td>
    <td>83.45</td>
    <td>85.16</td>
    <td>83.35</td>
    <td>81.61</td>
    <td>81.07</td>
    <td>76.29</td>
    <td>75.88</td>
  </tr>
  <tr>
    <td>Qwen2.5-7B</td>
    <td>79.60</td>
    <td>86.65</td>
    <td>88.55</td>
    <td>83.39</td>
    <td>85.17</td>
    <td>78.03</td>
    <td>80.79</td>
  </tr>
  <tr>
    <td>Qwen2.5-7B-Instruct</td>
    <td>79.51</td>
    <td>82.81</td>
    <td>83.73</td>
    <td>80.96</td>
    <td>80.85</td>
    <td>72.93</td>
    <td>74.40</td>
  </tr>
  <tr>
    <td>Qwen2.5-14B</td>
    <td>84.07</td>
    <td>90.40</td>
    <td>93.13</td>
    <td>86.46</td>
    <td>89.54</td>
    <td>84.31</td>
    <td>88.20</td>
  </tr>
  <tr>
    <td>Qwen2.5-14B-Instruct</td>
    <td>83.69</td>
    <td>86.47</td>
    <td>88.02</td>
    <td>83.17</td>
    <td>86.14</td>
    <td>78.94</td>
    <td>82.57</td>
  </tr>
  <tr>
    <td>BianCang-Qwen2-7B (Ours)</td>
    <td>83.27</td>
    <td>91.88</td>
    <td>93.31</td>
    <td>88.57</td>
    <td>90.72</td>
    <td>85.29</td>
    <td>88.47</td>
  </tr>
  <tr>
    <td>BianCang-Qwen2-7B-Instruct (Ours)</td>
    <td>84.08</td>
    <td>94.35</td>
    <td>94.35</td>
    <td>91.37</td>
    <td><b>91.64</b></td>
    <td>89.19</td>
    <td>90.02</td>
  </tr>
  <tr>
    <td>BianCang-Qwen2.5-7B (Ours)</td>
    <td>80.13</td>
    <td>90.43</td>
    <td>91.32</td>
    <td>85.65</td>
    <td>87.22</td>
    <td>82.19</td>
    <td>82.65</td>
  </tr>
  <tr>
    <td>BianCang-Qwen2.5-7B-Instruct (Ours)</td>
    <td>80.71</td>
    <td>93.40</td>
    <td>93.43</td>
    <td>89.91</td>
    <td>89.91</td>
    <td>86.43</td>
    <td>86.77</td>
  </tr>
  <tr>
    <td>BianCang-Qwen2.5-14B (Ours)</td>
    <td><b>84.34</b></td>
    <td>91.70</td>
    <td>93.37</td>
    <td>87.92</td>
    <td>89.97</td>
    <td>86.16</td>
    <td>87.94</td>
  </tr>
  <tr>
    <td>BianCang-Qwen2.5-14B-Instruct (Ours)</td>
    <td>83.80</td>
    <td><b>94.74</b></td>
    <td><b>94.97</b></td>
    <td><b>91.86</b></td>
    <td>91.53</td>
    <td><b>90.43</b></td>
    <td><b>90.51</b></td>
  </tr>
</table>

<div align="center">
<p>
    <img src="assets/subjective.png"/>
    </p>
</div>

æ›´å¤šæµ‹è¯„ç»“æœè¯·å…³æ³¨æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šã€‚

## ğŸ§¡è‡´è°¢

æœ¬é¡¹ç›®åŸºäºå¼€æºé¡¹ç›®è¿›è¡Œå¼€å‘ï¼Œåœ¨æ­¤å¯¹ç›¸å…³é¡¹ç›®å’Œç ”ç©¶å¼€å‘äººå‘˜è¡¨ç¤ºæ„Ÿè°¢ã€‚

- [Qwen2](https://github.com/vitanova/Qwen2)
- [Qwen2.5](https://github.com/QwenLM/Qwen2.5)
- [SWIFT](https://github.com/modelscope/ms-swift)
- [ModelScope](https://github.com/modelscope/modelscope)
- [ShenNong-TCM-LLM](https://github.com/michael-wzhu/ShenNong-TCM-LLM?tab=readme-ov-file)
- [HuatuoGPT-II](https://github.com/FreedomIntelligence/HuatuoGPT-II)
- [DISC-MedLLM](https://github.com/FudanDISC/DISC-MedLLM)
- [MLEC-QA](https://github.com/Judenpech/MLEC-QA)
- [CMB](https://github.com/FreedomIntelligence/CMB?tab=readme-ov-file)
- [ZY-BERT](https://github.com/Borororo/ZY-BERT)
- [COIG](https://github.com/BAAI-Zlab/COIG)
- [APE210k](https://github.com/Chenny0808/ape210k)
- [Evol-Instruction-66K](https://github.com/Continuum-Labs-HQ/EvolInstruct)


## â•å…è´£å£°æ˜

- æœ¬é¡¹ç›®ç›¸å…³èµ„æºä»…ä¾›å­¦æœ¯ç ”ç©¶ä¹‹ç”¨ã€‚
- æ‰ä»“ä¸­åŒ»å¤§æ¨¡å‹ä½œä¸ºåŸºäºè¯­è¨€æ¨¡å‹çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œå…·æœ‰å±€é™æ€§ï¼Œæ— æ³•ä¿è¯æ‰€æœ‰å“åº”çš„å‡†ç¡®æ€§ï¼Œå…¶ä¸èƒ½ä»£æ›¿ä¸­åŒ»/è¥¿åŒ»è¿›è¡ŒåŒ»å­¦è¯Šæ–­å’Œç»™å‡ºåŒ»å­¦å»ºè®®ã€‚å¦‚æœ‰éœ€è¦ï¼Œè¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿæˆ–å‰å¾€åŒ»é™¢å°±è¯Šã€‚
- ç”±äºåŒ»ç–—é¢†åŸŸçš„æ•°æ®ä¸å‡†ç¡®å¯èƒ½é€ æˆä¸¥é‡åæœï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®ç”¨æˆ·åœ¨å¤„ç†ç”Ÿæˆçš„ä¿¡æ¯æ—¶è¦å°å¿ƒè°¨æ…ï¼Œå¹¶å‘ä¸“å®¶å¯»æ±‚å»ºè®®ã€‚



